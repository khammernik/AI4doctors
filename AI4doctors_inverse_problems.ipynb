{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI4doctors_inverse_problems.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3FQfPO7E4wTw",
        "uZGtqU-H4sKW",
        "ZdaLmR1p5kI0",
        "pktZsAcf6atH",
        "6cd4d6F0IXjf",
        "PIA9scmCZAsd",
        "Prqq7W7pUt9p"
      ],
      "authorship_tag": "ABX9TyPzVWLPKPyw6ilPuRjeJ3Mx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khammernik/AI4doctors/blob/master/AI4doctors_inverse_problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This tutorial consists of two parts. In the first part, you will be playing with the task of image denoising and solving a linear and regularized reconstruction problem. Furthermore, we apply a pre-trained network to our unseen brain data. In the second part, you will get introduced to the world of MRI reconstruction. We start with examining the raw k-space data and coil-sensitivity maps and build the multi-coil forward and adjoint operator. Additionally, we solve a linear and a regularized reconstruction problem, allow us to deeply understand where we can connect with machine learning.\n",
        "\n",
        "First, we install the dependencies and download the data.\n",
        "\n",
        "Data were acquired on a 3T Siemens Magnetom Vida at the Institute of Biomedical Imaging, Graz University of Technology, Austria. Data should be only used for educational purpose."
      ],
      "metadata": {
        "id": "3FQfPO7E4wTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install PyWavelets git+https://github.com/khammernik/medutils.git"
      ],
      "metadata": {
        "id": "FMZis3rdoWvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download data\n",
        "!wget -O brain_cartesian_2D_removeOS.h5 https://www.dropbox.com/s/282e0nabg8l1ruh/brain_cartesian_2D_removeOS.h5?dl=1\n",
        "!wget -O brain_cartesian_2D.h5 https://www.dropbox.com/s/hclfv3re91qb1v3/brain_cartesian_2D.h5?dl=1\n",
        "!wget -O brain.npy https://www.dropbox.com/s/jphs92fn3mypqhx/brain.npy?dl=1\n",
        "!wget -O vrs_mask.npy https://www.dropbox.com/s/u4nj45gkk7ejb5a/vrs_mask.npy?dl=1"
      ],
      "metadata": {
        "id": "jbO9aJ7m4kq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Denoising\n",
        "This tutorial gives insights into the task of image denoising. The goal is to recover the clean image $u$, which is corrupted by additive Gaussian white noise $n$, given the noisy measurement data $f$,\n",
        "$$ f = u + n. $$\n",
        "\n",
        "The tutorial covers following denoising approaches:\n",
        "- Denoising with L2 regularization\n",
        "- Denoising with (smoothed) Total Variation (TV) regularization\n",
        "- Denoising with a deep neural network\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PLvG46jOoOhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "Next, we load a single image and prepare it for image denoising by normalizing it to the range $[0,1]$."
      ],
      "metadata": {
        "id": "uZGtqU-H4sKW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSV6lv_JoMF9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import medutils\n",
        "import numpy as np\n",
        "\n",
        "img = np.load('brain.npy')\n",
        "\n",
        "# make real-valued image\n",
        "img = np.abs(img)\n",
        "\n",
        "# normalize between [0,1]\n",
        "img /= np.max(img)\n",
        "\n",
        "# show image\n",
        "medutils.visualization.imshow(img, title='Original Image', figsize=(6,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare the quality of the denoising algorithms, we compute the Peak Signal to Noise ratio (PSNR) in dB as follows:\n",
        "$$ \\text{PSNR} = 10 \\log_{10} \\left(\\frac{\\text{max_intensity}^2}{\\text{MSE}}\\right),$$\n",
        "where the Mean-Squared error (MSE) is defined as:\n",
        "$$ \\text{MSE} = \\sum_{i\\in\\Omega} \\vert u_{\\text{ref},i} - u_i \\vert^2. $$\n",
        "Here, $u_{\\text{ref}}$ defines the target (reference) image, $u$ the source image, e.g., noisy or denoised image, and $i$ denote the pixels in domain $\\Omega$.\n",
        "\n"
      ],
      "metadata": {
        "id": "qFkjEcge47AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def psnr(x, x_ref, max_intensity=1.0):\n",
        "    \"\"\"\n",
        "    Compute the Peak Signal to Noise ratio (PSNR) in dB\n",
        "    Args:\n",
        "        x (np.array): predicted image\n",
        "        x_ref (np.array): target image\n",
        "    Return:\n",
        "        float: Computed metric\n",
        "    \"\"\"\n",
        "    return 10 * np.log10(max_intensity ** 2 / np.mean((x_ref-x)**2))"
      ],
      "metadata": {
        "id": "UScLP2fk4f8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we generate a noisy image $f$ by adding Gaussian white noise of standard deviation $\\sigma$.\n",
        "\n",
        "**Task: Experiment with different levels of noise.**"
      ],
      "metadata": {
        "id": "xxh44KSf5Sgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# noise level for domain [0, 255]\n",
        "sigma = 25\n",
        "\n",
        "# generate noisy image\n",
        "noisy = img + sigma / 255.0 * np.random.randn(*img.shape)\n",
        "\n",
        "# plot noisy image\n",
        "medutils.visualization.imshow(noisy, title=f'Noisy Image sigma={sigma} PSNR={psnr(noisy, img):0.2f} (dB)', figsize=(6,6))"
      ],
      "metadata": {
        "id": "8TVfvRAt5Kak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L2-H1 regularization\n",
        "We regularize the least-squares problem with a regularizer of form $\\mathcal{R}(u)=\\frac{1}{2} \\Vert \\nabla u \\Vert_2^2$, resulting in following minimization problem.\n",
        "\n",
        "$$ \\min_u \\frac{1}{2} \\Vert u - f \\Vert_2^2 + \\frac{\\lambda}{2} \\Vert \\nabla u \\Vert_2^2$$\n",
        "\n",
        "The solution is given as:\n",
        "\n",
        "$$ u - f + \\lambda\\nabla^\\top \\nabla u = 0 $$\n",
        "$$ u = (I + \\lambda \\nabla^\\top \\nabla)^{-1} f $$"
      ],
      "metadata": {
        "id": "ZdaLmR1p5kI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse\n",
        "import scipy.sparse.linalg\n",
        "\n",
        "def nabla_matrix(M, N):\n",
        "    \"\"\" Generates the nabla matrix for a 2D image of size [M, N] \"\"\"\n",
        "    size = M * N\n",
        "    row = np.arange(0, size)\n",
        "    col = np.arange(0, size).reshape(M, N)\n",
        "    fill = np.ones(size)\n",
        "    col_fwd_x = np.pad(col[:,1:], [[0, 0],[0, 1]], mode='edge')\n",
        "    col_bwd_y = np.pad(col[1:], [[0, 1],[0, 0]], mode='edge')\n",
        "\n",
        "    dx = scipy.sparse.coo_matrix((fill, (row, col_fwd_x.flatten())), shape=(size, size)) - \\\n",
        "         scipy.sparse.coo_matrix((fill, (row, col.flatten())), shape=(size, size))\n",
        "\n",
        "    dy = scipy.sparse.coo_matrix((fill, (row, col_bwd_y.flatten())), shape=(size, size)) - \\\n",
        "         scipy.sparse.coo_matrix((fill, (row, col.flatten())), shape=(size, size))\n",
        "\n",
        "    return scipy.sparse.vstack([dx, dy])\n",
        "\n",
        "def opt_l2h1(u, alpha):\n",
        "    \"\"\" Solve linear system of equations. \"\"\"\n",
        "    D = nabla_matrix(*u.shape)\n",
        "    v = scipy.sparse.linalg.spsolve(scipy.sparse.eye(u.size) + alpha * D.T @ D, u.flatten())\n",
        "    return np.reshape(v, u.shape)"
      ],
      "metadata": {
        "id": "aoEyihXA5ugK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 10 # regularization parameter\n",
        "denoised_l2h1 = opt_l2h1(noisy, alpha=alpha)\n",
        "\n",
        "medutils.visualization.imshow(denoised_l2h1, f'Denoised L2H1 alpha={alpha} PSNR={psnr(denoised_l2h1, img):0.2f} (dB)', figsize=(6,6))"
      ],
      "metadata": {
        "id": "t-BZFpCc506U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Denoising with Total Variation regularization.\n",
        "We see that the quadratic regularizer smoothes the entire image. To alleviate this issue, a total variation (TV) regularizer can be used. The TV is given as\n",
        "$$ \\mathcal{R}(u) = \\Vert \\nabla u \\Vert_{2,1} = \\sum_{i\\in\\Omega} \\sqrt{(\\nabla_x u_i)^2 + (\\nabla_y u_i)^2},$$ known as the ROF model, proposed by Rudin, Osher and Fatemi.\n",
        "Here, $\\nabla$ approximates the image gradient with finite forward differences.\n",
        "The TV regularizer approximates sparsity in the image edges and favors piece-wise constant solutions. However, the TV regularizer is not differentiable which makes it challenging to solve the optimization problem. One possibility is to use the primal-dual algorithm. At this point, you do not need to understand the algorithm in detail! It is more important to find out the characteristics of the algorithm by playing around with the regularization parameter.\n",
        "\n",
        "### Primal-Dual Algorithm\n",
        "One famous algorithm to solve above problem is the [Primal-Dual Algorithm](https://link.springer.com/article/10.1007/s10851-010-0251-1) (Chambolle & Pock, 2010). We only roughly outline the primal-dual algorithm in this tutorial. More information are found in the original publication Section 6.2.1.\n",
        "\n",
        "Consider the saddle-point problem\n",
        "$$ \\min_u \\max_p \\langle \\nabla u, p \\rangle + \\frac{\\lambda}{2}\\Vert u - f \\Vert_2^2 - \\delta_\n",
        "{\\Vert p \\Vert_{\\infty} \\leq 1}(p).$$\n",
        "\n",
        "\n",
        "Set $\\tau \\sigma L \\leq 1$, where $L$ is the Lipschitz constant, $\\tau$ is the primal stepsize and $\\sigma$ is the dual stepsize, respectively. Initialize $p^0=0$, $u^0=f$, $\\bar{u}^0=f$. Set regularization parameter $\\lambda$ and maximum number of iterations $N_k$.\n",
        "\n",
        "For $0 \\leq k < N_k$ do:\n",
        "\n",
        "1. Perform dual update\n",
        "$$ \\hat{p}^{k+1} = p^{k} + \\sigma \\nabla \\bar{u}^k$$\n",
        "\n",
        "2. Perform projection onto infinity ball\n",
        "$$ p^{k+1} = \\frac{\\hat{p}^{k+1}}{\\max{\\left(\\Vert \\hat{p}^{k+1} \\Vert_2, 1\\right)}}$$\n",
        "\n",
        "3. Perform primal update\n",
        "$$ \\hat{u}^{k+1} = u^{k} - \\tau \\nabla^\\top p^{k+1} $$\n",
        "\n",
        "4. Solve proximal mapping\n",
        "$$ u^{k+1} = \\arg \\min_u \\frac{1}{\\tau} \\Vert u - \\hat{u}^{k+1} \\Vert_2^2 + \\frac{\\lambda}{2}\\Vert u - f\\Vert_2^2 $$\n",
        "which results in the update\n",
        "$$ u^{k+1} = \\frac{\\hat{u}^{k+1} + \\tau \\lambda f\n",
        "}{1 + \\tau\\lambda} $$\n",
        "\n",
        "5. Overrelaxation\n",
        "$$ \\bar{u}^{k+1} = u^{k+1} + \\theta (u^{k+1} - u^{k})$$"
      ],
      "metadata": {
        "id": "pktZsAcf6atH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nabla(x):\n",
        "    dx = np.pad(x[:,1:], [[0, 0],[0, 1]], mode='edge')\n",
        "    dy = np.pad(x[1:], [[0, 1],[0, 0]], mode='edge')\n",
        "    return np.concatenate([dx[None,...] - x, dy[None,...] - x], 0)\n",
        "\n",
        "def nablaT(x):\n",
        "    assert x.shape[0] == 2\n",
        "    dx = np.pad(x[0,:,:-1], [[0, 0],[1, 1]], mode='constant')\n",
        "    dy = np.pad(x[1,:-1], [[1, 1],[0, 0]], mode='constant')\n",
        "    return dx[:,:-1] - dx[:,1:] + dy[:-1] - dy[1:]"
      ],
      "metadata": {
        "id": "6Nb52oPq89Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def primal_dual(f, alpha, max_iter):\n",
        "    p = np.zeros_like(nabla(f))\n",
        "    u = f.copy()\n",
        "    u_old = f.copy()\n",
        "    u_bar = f.copy()\n",
        "\n",
        "    L = 8.0\n",
        "    sigma = 1.0 / np.sqrt(L)\n",
        "    tau = 1.0 / np.sqrt(L)\n",
        "\n",
        "    theta = 1.0\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        # dual update\n",
        "        p_ = p.copy() + sigma * nabla(u_bar)\n",
        "        # dual projection\n",
        "        norm_p = np.sqrt(p_[0]**2 + p_[1]**2)\n",
        "        p = p_ / np.maximum(np.ones_like(norm_p), norm_p)\n",
        "        # primal update\n",
        "        u_ = u.copy() - tau * nablaT(p)\n",
        "        # primal proximal step\n",
        "        u = (u_ + tau * alpha * f) / (1 + tau * alpha)\n",
        "        # over-relaxation\n",
        "        u_bar = u + theta * (u - u_old)\n",
        "        u_old = u.copy()\n",
        "    return u"
      ],
      "metadata": {
        "id": "5LXmJNwjPNqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 10.0\n",
        "max_iter = 500\n",
        "denoised_pd = primal_dual(noisy, alpha=alpha, max_iter=max_iter)\n",
        "\n",
        "medutils.visualization.imshow(denoised_pd, f'Denoised Primal-Dual alpha={alpha} max_iter={max_iter} PSNR={psnr(denoised_pd, img):0.2f} (dB)', figsize=(6,6))"
      ],
      "metadata": {
        "id": "Xifnjq_5PSoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Denoising Network\n",
        "The following code downloads the DnCNN denoising network and applies it to our image denoising task. Note that the image was trained on natural images.\n",
        "\n",
        "Zhang et al. [Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising](https://ieeexplore.ieee.org/document/7839189). IEEE Transactions on Image Processing, vol. 26, no. 7, pp. 3142-3155, 2017."
      ],
      "metadata": {
        "id": "6cd4d6F0IXjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "if not os.path.exists('./trained_models'):\n",
        "    os.makedirs('./trained_models')\n",
        "\n",
        "if not os.path.exists('./trained_models/dncnn.json'):\n",
        "    os.system('wget https://raw.githubusercontent.com/cszn/DnCNN/master/TrainingCodes/dncnn_keras/models/DnCNN_sigma25/model.json -O ./trained_models/dncnn.json')\n",
        "\n",
        "if not os.path.exists('./trained_models/dncnn.h5'):\n",
        "    os.system('wget https://raw.githubusercontent.com/cszn/DnCNN/master/TrainingCodes/dncnn_keras/models/DnCNN_sigma25/model.h5 -O ./trained_models/dncnn.h5')\n",
        "\n",
        "json_file = open('trained_models/dncnn.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights('./trained_models/dncnn.h5')\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "B4oDL2pIGjCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_tf(x):\n",
        "    return x[None,...,None]\n",
        "\n",
        "def from_tf(x):\n",
        "    return np.squeeze(x)\n",
        "\n",
        "denoised_dncnn = from_tf(model.predict(to_tf(noisy)))\n",
        "\n",
        "medutils.visualization.imshow(denoised_dncnn, title=f'Denoised DnCNN PSNR={psnr(denoised_dncnn, img):0.2f} (dB)', figsize=(6,6))"
      ],
      "metadata": {
        "id": "ck0Ol-eQIgA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Magnetic Resonance Image (MRI) Reconstruction\n",
        "\n",
        "This tutorial gives insights into the task of MRI reconstruction. The goal is to recover the clean image $u$, which is obtained by undersampled k-space data $f$ and corrupted by additive Gaussian white noise $n$,\n",
        "$$ f = Au + n. $$\n",
        "The rawdata $f$ was aquired for multiple receive coils. The linear operator $A$ denotes the mapping from image space to k-space.\n",
        "\n"
      ],
      "metadata": {
        "id": "rN6i2t_WSAjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading\n",
        "\n",
        "In the first step, we examine the avaiable data regarding their shape and their datatype. Note, that we are dealing with complex-valued data here."
      ],
      "metadata": {
        "id": "PIA9scmCZAsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import medutils\n",
        "\n",
        "ds = h5py.File('./brain_cartesian_2D.h5', 'r')\n",
        "kspace = ds['kspace'][()]\n",
        "smaps = ds['smaps'][()]\n",
        "ds.close()\n",
        "\n",
        "print(f'K-Space:')\n",
        "print(f'dtype={kspace.dtype}')\n",
        "print(f'(nCoils, nFE, nPE)={kspace.shape}')\n",
        "nCoils, nFE, nPE = kspace.shape\n",
        "print('')\n",
        "print(f'Smaps:')\n",
        "print(f'dtype={smaps.dtype}')\n",
        "print(f'(nCoils, nFE, nPE)={smaps.shape}')"
      ],
      "metadata": {
        "id": "eNj1r9CqS8Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that we have 16 coils, the number of frequency encoding (readout) points `nFE` equals 640, and the number of phase encoding steps is 330. We will come back to this later."
      ],
      "metadata": {
        "id": "w_UitpW8VRdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization\n",
        "For data visualization, you are free to use any plotting library such as `matplotlib` or use the provided `medutils` package. The `medutils` package has some useful function for visualization:\n",
        "- `kshow` Process the data in log-space\n",
        "- `plot_array` Re-arrange the images from a 3D array next to each other.\n",
        "\n",
        "We will first visualize the `kspace` and the coil sensitivity maps `smaps`. The coil sensitivity maps are smooth maps that show us in which parts the single coil elements are sensitive. We will need these information for reconstruction.\n"
      ],
      "metadata": {
        "id": "Prqq7W7pUt9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medutils.visualization.kshow(medutils.visualization.plot_array(kspace, M=2, N=8), title='K-space', figsize=(40,20))"
      ],
      "metadata": {
        "id": "CO2e_OvXUwLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medutils.visualization.imshow(medutils.visualization.plot_array(smaps, M=2, N=8), title='Sensitivity Maps', figsize=(40,20))"
      ],
      "metadata": {
        "id": "OS7HflObXC--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now start to transform the `kspace` to single images. Therefore, we require the centered 2d inverse Fourier transform, which is contained in `medutils.mri.ifft2c`. Application of the `ifft2c` to the k-space results in single coil images."
      ],
      "metadata": {
        "id": "mt6WTnNqXq9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coil_img = medutils.mri.ifft2c(kspace)\n",
        "medutils.visualization.imshow(medutils.visualization.plot_array(coil_img, M=2, N=8), title='Coil Images', figsize=(40,20))"
      ],
      "metadata": {
        "id": "_zD9fi0BVzvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might notice several things. First, you see that only a fraction of the image is bright. This is due to the effect that the coils are sensitive only in a certain spatial region. Second, you might notice that there are a lot of black areas all over the image, especially in y direction. This extended field of view in read-out direction, also termed frequency-encoding direction is actually for free, does not cost any additional acquisition time, and is implemented per default on MRI scanners.  Assuming the base resolution is 320, the number of frequency encoding steps is doubled. This frequency oversampling results in an increased field-of-view in this direction. After the image is transformed to image domain, only the central part needs to be visualized. However, for display, we will from now on only consider the central part."
      ],
      "metadata": {
        "id": "Em5MdDLkYBYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity-Weighted Coil Combination\n",
        "Now, we have all ingredients to combine the image! Do you remember how the forward and adjoint MRI multi-coil operators are defined? These are required in the next step. We first compute the coil-combined image. Right now, there is no undersampling mask involved, i.e., it is set to all ones.\n",
        "\n",
        "Pruessmann et al. [SENSE: Sensitivity encoding for fast MRI](https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291522-2594%28199911%2942%3A5%3C952%3A%3AAID-MRM16%3E3.0.CO%3B2-S) Magnetic Resonance in Medicine, 43(5):952-962, 1999."
      ],
      "metadata": {
        "id": "tSEJEA8GZEqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_cc = medutils.mri.mriAdjointOp(kspace, smaps, np.ones_like(kspace), fft_axes=(-2,-1), coil_axis=0)\n",
        "img_cc = medutils.visualization.center_crop(img_cc, (nFE//2, nPE))\n",
        "medutils.visualization.imshow(img_cc, title='Combined image (sensitivity-weighted)', figsize=(8,8))\n"
      ],
      "metadata": {
        "id": "Xxwj3aQBYpVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersampling\n",
        "Now it is your turn! We require undersampling masks for acceleration `R`. Your task is to play around with different patterns:\n",
        "- only set a dense block of `nRef` lines in the center of k-space.\n",
        "- only set every `R`-th line\n",
        "- combine both\n",
        "- load variable density sampling from file `vrs_mask.npy`\n",
        "\n",
        "Note that the effective acceleration `Reff` is determined by the number of `nPE` lines divided by the sum of a single PE line in the mask."
      ],
      "metadata": {
        "id": "L0Fv8DY7ZxaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "R = 3\n",
        "nRef = 20\n",
        "mask = np.ones(nPE)\n",
        "#TODO: Set every R-th line to one\n",
        "#TODO: Set nRef center lines to one\n",
        "mask = np.load('vrs_mask.npy')\n",
        "Reff = mask.size/np.sum(mask)\n",
        "\n",
        "mask = mask.reshape(1, nPE).repeat(nFE, axis=0)\n",
        "\n",
        "mask_visualize = medutils.visualization.center_crop(mask, (10, nPE))\n",
        "medutils.visualization.imshow(mask_visualize, 'Undersampling mask')\n",
        "print(f'Reff={Reff:0.2g}')"
      ],
      "metadata": {
        "id": "08GrS1rcZw6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are ready to estimate the zero filling solution by applying the adjoint operator to the data, by applying the estimated undersampling mask `mask`. Play around with above mask configurations. How do the images change?"
      ],
      "metadata": {
        "id": "0zy-F7VAcHYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the adjoint operator to the data and use the newly created undersampling mask.\n",
        "img_cc_us = medutils.mri.mriAdjointOp(kspace, smaps, mask, fft_axes=(-2,-1), coil_axis=0)\n",
        "img_cc_us = medutils.visualization.center_crop(img_cc_us, (nFE//2, nPE))\n",
        "medutils.visualization.imshow(img_cc_us, 'Undersampled image (zero filling)', figsize=(6,6))"
      ],
      "metadata": {
        "id": "XFdaATXDb0E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear and Regularized Reconstruction\n",
        "Now, we are ready to implement linear and regularized reconstruction. We additionally need the gradient operator, implementing forward / backward differences in `D` and `DT`, and the multi-coil MRI forward and adjoint operators, `A` and `AH`, respectively."
      ],
      "metadata": {
        "id": "zFKJhOEBchbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nabla(x):\n",
        "    dx = np.pad(x[:,1:], [[0, 0],[0, 1]], mode='edge')\n",
        "    dy = np.pad(x[1:], [[0, 1],[0, 0]], mode='edge')\n",
        "    return np.concatenate([dx[None,...] - x, dy[None,...] - x], 0)\n",
        "\n",
        "def nablaT(x):\n",
        "    assert x.shape[0] == 2\n",
        "    dx = np.pad(x[0,:,:-1], [[0, 0],[1, 1]], mode='constant')\n",
        "    dy = np.pad(x[1,:-1], [[1, 1],[0, 0]], mode='constant')\n",
        "    return dx[:,:-1] - dx[:,1:] + dy[:-1] - dy[1:]\n",
        "\n",
        "D = lambda x: nabla(np.real(x)) + 1j * nabla(np.imag(x))\n",
        "DT= lambda x: nablaT(np.real(x)) + 1j * nablaT(np.imag(x))"
      ],
      "metadata": {
        "id": "XM58ogWNc4M6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = lambda x: medutils.mri.mriForwardOp(x, smaps, mask)\n",
        "AH = lambda x: medutils.mri.mriAdjointOp(x, smaps, mask)"
      ],
      "metadata": {
        "id": "anJOsdUec7cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving the linear reconstruction problem\n",
        "Consider the following minimization problem:\n",
        "\n",
        "$$ \\min_x  E(x,y) = \\min_x \\Vert Ax - y \\Vert_2^2 $$\n",
        "\n",
        "While in image denoising we are still able to compute a closed-form solution for this problem, this is not feasible for the task of MRI reconstruction any more. We instead use first-order optimization methods and solve this by Gradient Descent:\n",
        "$$ x^{t+1} = x^{t} - \\alpha \\nabla_x E(x,y) $$\n",
        "$$ x^{t+1} = x^{t} - \\alpha A^H (Ax^t - y) $$"
      ],
      "metadata": {
        "id": "oiFZ3aR7dT_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def opt_linear(y, max_iter=10, alpha=0.1):\n",
        "    x = np.zeros_like(AH(y))\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        x = x - alpha * AH(A(x) - y)\n",
        "    return x"
      ],
      "metadata": {
        "id": "d2h7OIo1dN64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=1\n",
        "img_linear = opt_linear(kspace, max_iter=10, alpha=alpha)\n",
        "img_linear = medutils.visualization.center_crop(img_linear, (nFE//2, nPE))\n",
        "medutils.visualization.imshow(img_linear, f'Linear reconstruction alpha={alpha}', figsize=(6,6))"
      ],
      "metadata": {
        "id": "zTkILw7GeOEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L2-H1 Regularization\n",
        "\n",
        "Similar to image denoising above, we regularize the least-squares problem with a regularizer of form $\\mathcal{R}(x)=\\frac{1}{2} \\Vert \\nabla x \\Vert_2^2$, resulting in following minimization problem.\n",
        "Consider now the following minimization problem\n",
        "\n",
        "$$ \\min_x  D(x,y) + \\lambda R(x) = \\min_x \\frac{1}{2}\\Vert Ax - y \\Vert_2^2 + \\frac{\\lambda}{2}\\Vert \\nabla x \\Vert_2^2.$$\n",
        "\n",
        "In the easiest way, we solve this by Gradient Descent:\n",
        "$$ x^{t+1} = x^{t} - \\alpha \\left( \\nabla_x D(x,y) + \\nabla_x R(x) \\right) $$\n",
        "$$ x^{t+1} = x^{t} - \\alpha \\left( A^H (Ax^t - y) + \\lambda \\nabla^T \\nabla x \\right) $$"
      ],
      "metadata": {
        "id": "ziFJr1Mpe0re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def opt_reg_l2(y, max_iter=10, alpha=0.1, lambd=1.0):\n",
        "    x = np.zeros_like(AH(y))\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        x = x - alpha * (AH(A(x) - y) + lambd * DT(D(x)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "OIk8_dJJe0N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "lambd = 2.0\n",
        "img_reg_l2 = opt_reg_l2(kspace, max_iter=100, alpha=alpha, lambd=lambd)\n",
        "img_reg_l2 = medutils.visualization.center_crop(img_reg_l2, (nFE//2, nPE))\n",
        "medutils.visualization.imshow(img_reg_l2, f'L2H1 reconstruction alpha={alpha} lambda={lambd}', figsize=(6,6))"
      ],
      "metadata": {
        "id": "6rDK8F2Ie1gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse MRI: Wavelet Thresholding\n",
        "Medical images per se are not sparse, however, they might have a sparse representation in some transform domain. One example here is the Wavelet transform, resulting in a multi-level feature representation. We provide the `plot_wavedec` function to find out how the sparse images look like at different scales and orientations.\n",
        "\n",
        "We perform an optimization first wrt. data consistency term. This is followed by a Wavelet transform, and the Wavelet coefficients are surpressed by using soft-thresholding, i.e.,\n",
        "\n",
        "$$\n",
        "\\text{thresh}(x) = \\frac{x}{\\vert x \\vert}\\max(\\vert x \\vert - \\alpha\\lambda , 0)\n",
        "$$\n",
        "\n",
        "Hint: Note, that the absolut value could get zero, and a small epsilon might be adorable to surpress this.\n",
        "\n",
        "### Suggested Readings\n",
        "\n",
        "Lustig et al. [Compressed Sensing MRI](https://ieeexplore.ieee.org/document/4472246), IEEE Signal Processing Magazine 25(2):72-82, 2008.\n",
        "\n",
        "Lustig et al. [Sparse MRI: The application of compressed sensing for rapid MR imaging](https://onlinelibrary.wiley.com/doi/full/10.1002/mrm.21391). Magnetic Resonance in Medicine 58(6):1182-1195, 2007."
      ],
      "metadata": {
        "id": "DgHKKicfgExG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "\n",
        "def plot_wavedec(img, wavelet='db4', level=2):\n",
        "    img = medutils.visualization.center_crop(img_cc, (nFE//2, nPE))\n",
        "    coeffs = pywt.wavedecn(img, wavelet=wavelet, level=level)\n",
        "    # normalize coeffs\n",
        "    coeffs[0] /= np.max(np.abs(coeffs[0]))\n",
        "    for level in range(1, len(coeffs)):\n",
        "        for key in coeffs[level].keys():\n",
        "            coeffs[level][key] /= np.max(np.abs(coeffs[level][key]))\n",
        "    arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n",
        "    medutils.visualization.imshow(arr, figsize=(10,10))\n",
        "\n",
        "def soft_thresh(x, tau):\n",
        "    return x / np.maximum(np.abs(x), 1e-9) * np.maximum(np.abs(x) - tau, 0)\n",
        "\n",
        "def opt_reg_wavelet(y, max_iter=10, alpha=0.1, lambd=1.0, wavelet='db4', level=3):\n",
        "    x = np.zeros_like(AH(y))\n",
        "    wavelet_object = pywt.Wavelet(wavelet)\n",
        "    threshold = alpha * lambd\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        x = x - alpha * (AH(A(x) - y))\n",
        "        coeffs = pywt.wavedecn(x, wavelet_object, level=level)\n",
        "        array, coeff_slices = pywt.coeffs_to_array(coeffs)\n",
        "        denoised_array=soft_thresh(array, threshold)\n",
        "        denoised_coeffs = pywt.array_to_coeffs(denoised_array, coeff_slices, output_format='wavedecn')\n",
        "        x = pywt.waverecn(denoised_coeffs, wavelet_object)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "nIeuyuFtgEMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_wavedec(img_cc, level=3)"
      ],
      "metadata": {
        "id": "W2RfjPmygfCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambd=2e-5\n",
        "alpha=0.1\n",
        "img_reg_wavelet = opt_reg_wavelet(kspace, max_iter=400, alpha=alpha, lambd=lambd)\n",
        "img_reg_wavelet = medutils.visualization.center_crop(img_reg_wavelet, (nFE//2, nPE))\n",
        "medutils.visualization.imshow(img_reg_wavelet, f'Wavelet reconstruction alpha={alpha} lambda={lambd}', figsize=(6,6))"
      ],
      "metadata": {
        "id": "wnDICemEgub_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are ready to understand where the iterative (lower) level comes from and how this optimization can be optimized. Sometimese it is really important to step back a bit and look at classical approaches. :)"
      ],
      "metadata": {
        "id": "ApXgDAsiyH8V"
      }
    }
  ]
}